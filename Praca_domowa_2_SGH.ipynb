{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Praca domowa 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielMalinowski/WarsztatPythonDataScience/blob/master/Praca_domowa_2_SGH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9lqwq0OF8gY",
        "colab_type": "code",
        "outputId": "7c72ba78-20c8-407f-e880-83dcad586a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text_orig = \"\"\"For those working around Data Science, Machine Learning and or Artificial Intelligence, NLP is probably one of the most exciting fields to work in.\n",
        "NLP stands for Natural Language Processing and it’s about the interactions between computers and human languages. Programming algorithms capable of processing and analyzing large amounts of natural language data.\n",
        "The underlying objective may vary, but the overall goal is to get to conclusions about human behaviour…our intentions when writing something, what we were thinking or feeling when we do it, the category of an item we were writing about, and some other stuff like chatbots, market segmentation of customers, find duplicates and similarities in between elements, virtual assistants (like Siri or Alexa) and much more stuff.\n",
        "Nonetheless, NLP as a subject didn’t appear much time ago, it was just in 1960 when Alan Turing published an article called “Computing Machinery and Intelligence” which proposed what is now called the ‘Turing test’. The paper introduced the question ‘Can machines think?’ and the test proves a machine’s ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human. Three participants are necessary for running the test, where a player C, the evaluator, is given the task of trying to determine which player — A or B — is a computer and which is a human.\n",
        "The evaluator would then judge natural language conversations between a human and a machine designed to generate human-like responses, knowing that one of the two partners in conversation is a machine. The conversation would be limited to a text-only channel and the results do not depend on the machine’s ability to give correct answers to questions, only how closely its answers resemble those a human would give. If at the end of the test the evaluator cannot reliably tell the machine from the human, the machine is said to have passed the test.\n",
        "Starting from there, in the past years, the field has evolved exponentially, going from hand-coded systems using a set of rules, to a more sophisticated statistical NLP. And in this context, some companies are doing some pretty exciting stuff in the field. For example, if you’re an Android user you’re probably familiar with Swiftkey, a startup using text prediction designed to boost the accuracy, fluency and speed of users’ writing. Swiftkey learns from our writing, predicting favourite words, emojis and even expressions. Another startup, SignAll, converts sign language into text. Helping individuals who are deaf communicate with those who don’t know sign language.\n",
        "And the fact is that nowadays the expansion of some open source libraries using Python, Tensorflow, Keras and others, has made NLP accessible and each day more and more businesses are using it. Some of them hiring other companies specifically specialized in the subject, but some others are hiring Data Scientists and Data Analyst in order to build their own solutions.\n",
        "If any of these is your case, whether you are the company or the data specialist, in the next lines I will introduce some of my learning while working with NLP. Lucky for you, all of them are mistake-based tips! So hopefully, you will be able to avoid them in advance, not as it happened to me :)\n",
        "\"\"\"\n",
        "open('out.txt', 'w').write(text_orig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC62tsdcF8dr",
        "colab_type": "code",
        "outputId": "a8e4f216-37ea-41e4-814a-9f4378cde488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "text = open('out.txt', 'r').read().lower()\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for those working around data science, machine learning and or artificial intelligence, nlp is probably one of the most exciting fields to work in.\\nnlp stands for natural language processing and it’s about the interactions between computers and human languages. programming algorithms capable of processing and analyzing large amounts of natural language data.\\nthe underlying objective may vary, but the overall goal is to get to conclusions about human behaviour…our intentions when writing something, what we were thinking or feeling when we do it, the category of an item we were writing about, and some other stuff like chatbots, market segmentation of customers, find duplicates and similarities in between elements, virtual assistants (like siri or alexa) and much more stuff.\\nnonetheless, nlp as a subject didn’t appear much time ago, it was just in 1960 when alan turing published an article called “computing machinery and intelligence” which proposed what is now called the ‘turing test’. the paper introduced the question ‘can machines think?’ and the test proves a machine’s ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human. three participants are necessary for running the test, where a player c, the evaluator, is given the task of trying to determine which player — a or b — is a computer and which is a human.\\nthe evaluator would then judge natural language conversations between a human and a machine designed to generate human-like responses, knowing that one of the two partners in conversation is a machine. the conversation would be limited to a text-only channel and the results do not depend on the machine’s ability to give correct answers to questions, only how closely its answers resemble those a human would give. if at the end of the test the evaluator cannot reliably tell the machine from the human, the machine is said to have passed the test.\\nstarting from there, in the past years, the field has evolved exponentially, going from hand-coded systems using a set of rules, to a more sophisticated statistical nlp. and in this context, some companies are doing some pretty exciting stuff in the field. for example, if you’re an android user you’re probably familiar with swiftkey, a startup using text prediction designed to boost the accuracy, fluency and speed of users’ writing. swiftkey learns from our writing, predicting favourite words, emojis and even expressions. another startup, signall, converts sign language into text. helping individuals who are deaf communicate with those who don’t know sign language.\\nand the fact is that nowadays the expansion of some open source libraries using python, tensorflow, keras and others, has made nlp accessible and each day more and more businesses are using it. some of them hiring other companies specifically specialized in the subject, but some others are hiring data scientists and data analyst in order to build their own solutions.\\nif any of these is your case, whether you are the company or the data specialist, in the next lines i will introduce some of my learning while working with nlp. lucky for you, all of them are mistake-based tips! so hopefully, you will be able to avoid them in advance, not as it happened to me :)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvx7x4EfF8bJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "text = re.sub('\\n|\\r', ' ', text)\n",
        "text = ''.join(re.findall(r'[a-zA-Z ]', text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRaZuK5OHAhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_set = set()\n",
        "text_split = tuple(text.strip(' ').split(' '))\n",
        "for word in text_split:\n",
        "    word_set.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aeL2YGwF8Wa",
        "colab_type": "code",
        "outputId": "cfc72fdb-ded6-4b26-8c3e-2a5a107c26d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "occurences = dict()\n",
        "for word in word_set:\n",
        "    occurences[word] = text_split.count(word)\n",
        "occurences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 3,\n",
              " 'a': 15,\n",
              " 'ability': 2,\n",
              " 'able': 1,\n",
              " 'about': 3,\n",
              " 'accessible': 1,\n",
              " 'accuracy': 1,\n",
              " 'advance': 1,\n",
              " 'ago': 1,\n",
              " 'alan': 1,\n",
              " 'alexa': 1,\n",
              " 'algorithms': 1,\n",
              " 'all': 1,\n",
              " 'amounts': 1,\n",
              " 'an': 3,\n",
              " 'analyst': 1,\n",
              " 'analyzing': 1,\n",
              " 'and': 20,\n",
              " 'android': 1,\n",
              " 'another': 1,\n",
              " 'answers': 2,\n",
              " 'any': 1,\n",
              " 'appear': 1,\n",
              " 'are': 7,\n",
              " 'around': 1,\n",
              " 'article': 1,\n",
              " 'artificial': 1,\n",
              " 'as': 2,\n",
              " 'assistants': 1,\n",
              " 'at': 1,\n",
              " 'avoid': 1,\n",
              " 'b': 1,\n",
              " 'be': 2,\n",
              " 'behaviour': 1,\n",
              " 'behaviourour': 1,\n",
              " 'between': 3,\n",
              " 'boost': 1,\n",
              " 'build': 1,\n",
              " 'businesses': 1,\n",
              " 'but': 2,\n",
              " 'c': 1,\n",
              " 'called': 2,\n",
              " 'can': 1,\n",
              " 'cannot': 1,\n",
              " 'capable': 1,\n",
              " 'case': 1,\n",
              " 'category': 1,\n",
              " 'channel': 1,\n",
              " 'chatbots': 1,\n",
              " 'closely': 1,\n",
              " 'communicate': 1,\n",
              " 'companies': 2,\n",
              " 'company': 1,\n",
              " 'computer': 1,\n",
              " 'computers': 1,\n",
              " 'computing': 1,\n",
              " 'conclusions': 1,\n",
              " 'context': 1,\n",
              " 'conversation': 2,\n",
              " 'conversations': 1,\n",
              " 'converts': 1,\n",
              " 'correct': 1,\n",
              " 'customers': 1,\n",
              " 'data': 5,\n",
              " 'day': 1,\n",
              " 'deaf': 1,\n",
              " 'depend': 1,\n",
              " 'designed': 2,\n",
              " 'determine': 1,\n",
              " 'didnt': 1,\n",
              " 'do': 2,\n",
              " 'doing': 1,\n",
              " 'dont': 1,\n",
              " 'duplicates': 1,\n",
              " 'each': 1,\n",
              " 'elements': 1,\n",
              " 'emojis': 1,\n",
              " 'end': 1,\n",
              " 'equivalent': 1,\n",
              " 'evaluator': 3,\n",
              " 'even': 1,\n",
              " 'evolved': 1,\n",
              " 'example': 1,\n",
              " 'exciting': 2,\n",
              " 'exhibit': 1,\n",
              " 'expansion': 1,\n",
              " 'exponentially': 1,\n",
              " 'expressions': 1,\n",
              " 'fact': 1,\n",
              " 'familiar': 1,\n",
              " 'favourite': 1,\n",
              " 'feeling': 1,\n",
              " 'field': 2,\n",
              " 'fields': 1,\n",
              " 'find': 1,\n",
              " 'fluency': 1,\n",
              " 'for': 5,\n",
              " 'from': 5,\n",
              " 'generate': 1,\n",
              " 'get': 1,\n",
              " 'give': 2,\n",
              " 'given': 1,\n",
              " 'goal': 1,\n",
              " 'going': 1,\n",
              " 'handcoded': 1,\n",
              " 'happened': 1,\n",
              " 'has': 2,\n",
              " 'have': 1,\n",
              " 'helping': 1,\n",
              " 'hiring': 2,\n",
              " 'hopefully': 1,\n",
              " 'how': 1,\n",
              " 'human': 7,\n",
              " 'humanlike': 1,\n",
              " 'i': 1,\n",
              " 'if': 3,\n",
              " 'in': 11,\n",
              " 'indistinguishable': 1,\n",
              " 'individuals': 1,\n",
              " 'intelligence': 2,\n",
              " 'intelligent': 1,\n",
              " 'intentions': 1,\n",
              " 'interactions': 1,\n",
              " 'into': 1,\n",
              " 'introduce': 1,\n",
              " 'introduced': 1,\n",
              " 'is': 10,\n",
              " 'it': 4,\n",
              " 'item': 1,\n",
              " 'its': 2,\n",
              " 'judge': 1,\n",
              " 'just': 1,\n",
              " 'keras': 1,\n",
              " 'know': 1,\n",
              " 'knowing': 1,\n",
              " 'language': 5,\n",
              " 'languages': 1,\n",
              " 'large': 1,\n",
              " 'learning': 2,\n",
              " 'learns': 1,\n",
              " 'libraries': 1,\n",
              " 'like': 2,\n",
              " 'limited': 1,\n",
              " 'lines': 1,\n",
              " 'lucky': 1,\n",
              " 'machine': 5,\n",
              " 'machinery': 1,\n",
              " 'machines': 3,\n",
              " 'made': 1,\n",
              " 'market': 1,\n",
              " 'may': 1,\n",
              " 'me': 1,\n",
              " 'mistakebased': 1,\n",
              " 'more': 4,\n",
              " 'most': 1,\n",
              " 'much': 2,\n",
              " 'my': 1,\n",
              " 'natural': 3,\n",
              " 'necessary': 1,\n",
              " 'next': 1,\n",
              " 'nlp': 6,\n",
              " 'nonetheless': 1,\n",
              " 'not': 2,\n",
              " 'now': 1,\n",
              " 'nowadays': 1,\n",
              " 'objective': 1,\n",
              " 'of': 16,\n",
              " 'on': 1,\n",
              " 'one': 2,\n",
              " 'only': 1,\n",
              " 'open': 1,\n",
              " 'or': 6,\n",
              " 'order': 1,\n",
              " 'other': 2,\n",
              " 'others': 2,\n",
              " 'our': 1,\n",
              " 'overall': 1,\n",
              " 'own': 1,\n",
              " 'paper': 1,\n",
              " 'participants': 1,\n",
              " 'partners': 1,\n",
              " 'passed': 1,\n",
              " 'past': 1,\n",
              " 'player': 2,\n",
              " 'predicting': 1,\n",
              " 'prediction': 1,\n",
              " 'pretty': 1,\n",
              " 'probably': 2,\n",
              " 'processing': 2,\n",
              " 'programming': 1,\n",
              " 'proposed': 1,\n",
              " 'proves': 1,\n",
              " 'published': 1,\n",
              " 'python': 1,\n",
              " 'question': 1,\n",
              " 'questions': 1,\n",
              " 'reliably': 1,\n",
              " 'resemble': 1,\n",
              " 'responses': 1,\n",
              " 'results': 1,\n",
              " 'rules': 1,\n",
              " 'running': 1,\n",
              " 'said': 1,\n",
              " 'science': 1,\n",
              " 'scientists': 1,\n",
              " 'segmentation': 1,\n",
              " 'set': 1,\n",
              " 'sign': 2,\n",
              " 'signall': 1,\n",
              " 'similarities': 1,\n",
              " 'siri': 1,\n",
              " 'so': 1,\n",
              " 'solutions': 1,\n",
              " 'some': 7,\n",
              " 'something': 1,\n",
              " 'sophisticated': 1,\n",
              " 'source': 1,\n",
              " 'specialist': 1,\n",
              " 'specialized': 1,\n",
              " 'specifically': 1,\n",
              " 'speed': 1,\n",
              " 'stands': 1,\n",
              " 'starting': 1,\n",
              " 'startup': 2,\n",
              " 'statistical': 1,\n",
              " 'stuff': 3,\n",
              " 'subject': 2,\n",
              " 'swiftkey': 2,\n",
              " 'systems': 1,\n",
              " 'task': 1,\n",
              " 'tell': 1,\n",
              " 'tensorflow': 1,\n",
              " 'test': 5,\n",
              " 'text': 2,\n",
              " 'textonly': 1,\n",
              " 'that': 3,\n",
              " 'the': 34,\n",
              " 'their': 1,\n",
              " 'them': 3,\n",
              " 'then': 1,\n",
              " 'there': 1,\n",
              " 'these': 1,\n",
              " 'think': 1,\n",
              " 'thinking': 1,\n",
              " 'this': 1,\n",
              " 'those': 3,\n",
              " 'three': 1,\n",
              " 'time': 1,\n",
              " 'tips': 1,\n",
              " 'to': 16,\n",
              " 'trying': 1,\n",
              " 'turing': 2,\n",
              " 'two': 1,\n",
              " 'underlying': 1,\n",
              " 'user': 1,\n",
              " 'users': 1,\n",
              " 'using': 4,\n",
              " 'vary': 1,\n",
              " 'virtual': 1,\n",
              " 'was': 1,\n",
              " 'we': 3,\n",
              " 'were': 2,\n",
              " 'what': 2,\n",
              " 'when': 3,\n",
              " 'where': 1,\n",
              " 'whether': 1,\n",
              " 'which': 3,\n",
              " 'while': 1,\n",
              " 'who': 2,\n",
              " 'will': 2,\n",
              " 'with': 3,\n",
              " 'words': 1,\n",
              " 'work': 1,\n",
              " 'working': 2,\n",
              " 'would': 3,\n",
              " 'writing': 4,\n",
              " 'years': 1,\n",
              " 'you': 3,\n",
              " 'your': 1,\n",
              " 'youre': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGMwWh2OM4s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}